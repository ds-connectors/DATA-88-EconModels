{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%;\" id=\"nb-header>\">\n",
    "        <tr style=\"background-color: transparent;\"><td>\n",
    "            <img src=\"https://ds-connectors.github.io/econ-fa19/assets/images/blue_text.png\" width=\"250px\" style=\"margin-left: 0;\" />\n",
    "        </td><td>\n",
    "            <p style=\"text-align: right; font-size: 10pt;\"><strong>Economic Models</strong>, Spring 2020<br>\n",
    "                Dr. Eric Van Dusen<br>\n",
    "            Notebook by Andrei Caprau<br>\n",
    "            Based on \"Does the Stock Market Overreact?\" by De Bondt and Thaler</p></td></tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Economics Demonstration\n",
    "\n",
    "In this demonstration we'll attempt to repeat the procedure De Bondt and Thaler use to show that people tend to \"overreact\" to sudden and dramatic news events, and that these overreactions are evident in stock prices.\n",
    "\n",
    "This demonstration differs from De Bondt and Thaler's paper in that their data consisted of the prices of all stocks available to them from the Center for Research in Security Prices at the University of Chicago between 1926 and 1982. As such a large dataset of historical stock prices is difficult to obtain, we instead limit our data to a small selection of the largest public firms with listed prices between 2000 and 2019. As such, we will be cutting some corners and we will not produce statistically significant results as De Bondt and Thaler did. Furthermore, whatever results we do obtain we cannot extrapolate to the entire stock market as we have a potentially biased sample of stocks. We will be ignoring these problems entirely for now, and rather we will focus on the procedure itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure with one stock\n",
    "\n",
    "Let's show how the data are cleaned and prepared for the study by first looking at only one stock. Let's load in data on AAPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import these to allow us to read in files into the notebook.\n",
    "import os, sys\n",
    "\n",
    "# Numpy will allow us to work nicely with arrays. Pandas is a data \n",
    "# science package, much like the datascience package (confused yet?) \n",
    "# but better. Pandas is used in industry and in your future data \n",
    "# science classes.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# This allows us to perform regular expressions. Don't worry about this.\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = pd.read_csv('data/AAPL.csv')\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also load in data on dividends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_div = pd.read_csv('dividends/AAPL.csv')\n",
    "aapl_div.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine these two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = aapl.join(aapl_div.set_index(keys='Date'), on='Date', how='left')\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl['Dividends'] = aapl['Dividends'].fillna(value=0)\n",
    "aapl['Adj Close'] = aapl['Adj Close'] + aapl['Dividends']\n",
    "aapl = aapl.drop(columns=['Dividends'])\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're only interested in monthly returns. To find this, we'll only look look at the closing price on the first day of each month. So let's do that. We create a column named 'First' which has the value 1 if the day in question is the first day of the month and 0 otherwise. We then reduce our dataset do just days where 'First' is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl['Year'] = aapl['Date'].str.split(r'-').str[0].astype(int)\n",
    "aapl['Month'] = aapl['Date'].str.split(r'-').str[1].astype(int)\n",
    "aapl['Day'] = aapl['Date'].str.split(r'-').str[2].astype(int)\n",
    "aapl = aapl[['Year', 'Month', 'Day', 'Adj Close']]\n",
    "\n",
    "aapl['PrevDay'] = aapl['Day'].shift().fillna(value=999).astype(int)\n",
    "aapl['First'] = aapl.apply(lambda row: 1 if row['PrevDay'] > row['Day'] else 0, axis=1)\n",
    "\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = aapl[aapl['First'] == 1]\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to find the return for a particular month. To do this, we'll create a new column that is simply the column of closing price shifted down one. That way, each row not only has the closing price for that month, but also the month before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = aapl.drop(columns=['Day', 'PrevDay', 'First'])\n",
    "aapl['Prev Close'] = aapl['Adj Close'].shift()\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the first row has no value for 'Prev Close'. Think very briefly about why that is. Let's drop that first row, and calculate return as a proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = aapl.drop(index=0)\n",
    "aapl['Return'] = aapl.apply(lambda row: (row['Adj Close'] - row['Prev Close']) \n",
    "                        / row['Prev Close'], axis=1)\n",
    "aapl = aapl.reset_index(drop=True)\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose SPY to act as a proxy measurement for the performance of the market as a whole. Data on SPY is easy to obtain and has the same general form as AAPL data above. Let's do the same data manipulations on SPY as we did on AAPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy = pd.read_csv('data/SPY.csv')\n",
    "spy_dividends = pd.read_csv('dividends/SPY.csv')\n",
    "spy = spy.join(spy_dividends.set_index(keys='Date'), on='Date', how='left')\n",
    "spy['Dividends'] = spy['Dividends'].fillna(value=0)\n",
    "spy['Adj Close'] = spy['Adj Close'] + spy['Dividends']\n",
    "spy = spy.drop(columns=['Dividends'])\n",
    "spy['Year'] = spy['Date'].str.split(r'-').str[0].astype(int)\n",
    "spy['Month'] = spy['Date'].str.split(r'-').str[1].astype(int)\n",
    "spy['Day'] = spy['Date'].str.split(r'-').str[2].astype(int)\n",
    "spy = spy[['Year', 'Month', 'Day', 'Adj Close']]\n",
    "spy['PrevDay'] = spy['Day'].shift().fillna(value=999).astype(int)\n",
    "spy['First'] = spy.apply(lambda row: 1 if row['PrevDay'] > row['Day'] else 0, axis=1)\n",
    "spy = spy[spy['First'] == 1]\n",
    "spy = spy.drop(columns=['Day', 'PrevDay', 'First'])\n",
    "spy['Prev Close'] = spy['Adj Close'].shift()\n",
    "spy = spy.drop(index=0)\n",
    "spy['Return'] = spy.apply(lambda row: (row['Adj Close'] - row['Prev Close']) \n",
    "                        / row['Prev Close'], axis=1)\n",
    "spy = spy.reset_index(drop=True)\n",
    "spy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Now let's create a new column in AAPL that has the corresponding SPY return for each monthly return of AAPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl['SPY Return'] = spy['Return']\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find excess return, which is the return of AAPL minus the return of SPY. It is a measure of how much better (or worse) AAPL's returns are compared to the market return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl['Excess Return'] = aapl['Return'] - aapl['SPY Return']\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the monthly excess return for AAPL. Ideally we want to repeat this for every listed stock, but for now we only have a small subset of stocks to work with. As a result, our results are insignificant (and probably biased) and we are unable to come to De Bondt and Thaler's conclusions. However, we'll continue anyway so that we can get an idea and appreciation for what the process might feel like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure with multiple stocks\n",
    "\n",
    "First, let's repeat what we did above with AAPL but now with a larger subset of stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of our stock data, along with this notebook, are stored somewhere. \n",
    "# This gets that location.\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Here we read in the data for each stock that we have.\n",
    "data = {}\n",
    "for csv in os.listdir(cwd + '/data'):\n",
    "    if csv == '.DS_Store':\n",
    "        continue\n",
    "    df = pd.read_csv('data/' + csv)\n",
    "    data[re.findall(r'.+\\.', str(csv))[0][:-1]] = df[['Date', 'Adj Close']]\n",
    "    \n",
    "# We also read in the data for dividends that were paid out for each \n",
    "# company.\n",
    "dividends = {}\n",
    "for csv in os.listdir(cwd + '/dividends'):\n",
    "    if csv == '.DS_Store':\n",
    "        continue\n",
    "    dividends[re.findall(r'.+\\.', str(csv))[0][:-1]] = pd.read_csv('dividends/' + csv)\n",
    "\n",
    "# Here, we add dividend payouts to the closing prices of each stock, \n",
    "# since dividends must be included when calculating the return of a stock.\n",
    "for stock in dividends.keys():\n",
    "    df = data[stock]\n",
    "    \n",
    "    df = df.join(dividends[stock].set_index(keys='Date'), on='Date', how='left')\n",
    "    \n",
    "    df['Dividends'] = df['Dividends'].fillna(value=0)\n",
    "    df['Adj Close'] = df['Adj Close'] + df['Dividends']\n",
    "    df = df.drop(columns=['Dividends'])\n",
    "    \n",
    "    data[stock] = df\n",
    "\n",
    "# Here we find out which days are the first days of the month, and we only \n",
    "# keep those days. Then, we create a new column that is the column \n",
    "# containing closing prices, but shifted down one row. This allows us \n",
    "# to compare the closing price in one month to the previous month, and \n",
    "# thus the return in that month.\n",
    "for stock in data.keys():\n",
    "    df = data[stock]\n",
    "    \n",
    "    df['Year'] = df['Date'].str.split(r'-').str[0].astype(int)\n",
    "    df['Month'] = df['Date'].str.split(r'-').str[1].astype(int)\n",
    "    df['Day'] = df['Date'].str.split(r'-').str[2].astype(int)\n",
    "    df = df[['Year', 'Month', 'Day', 'Adj Close']]\n",
    "    \n",
    "    df['PrevDay'] = df['Day'].shift().fillna(value=999).astype(int)\n",
    "    df['First'] = df.apply(lambda row: 1 if row['PrevDay'] > row['Day'] else 0, axis=1)\n",
    "    df = df[df['First'] == 1]\n",
    "    \n",
    "    df = df.drop(columns=['Day', 'PrevDay', 'First'])\n",
    "    df['Prev Close'] = df['Adj Close'].shift()\n",
    "    df = df.drop(index=0)\n",
    "    \n",
    "    df['Return'] = df.apply(lambda row: (row['Adj Close'] - row['Prev Close']) \n",
    "                            / row['Prev Close'], axis=1)\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    data[stock] = df\n",
    "\n",
    "# We now add the return of $SPY, which will act as a proxy for market \n",
    "# return. We can then find excess return, which is a company's return \n",
    "# minus the return of the market.\n",
    "SPY_return = data['SPY']['Return']\n",
    "for stock in data.keys():\n",
    "    if stock == 'SPY':\n",
    "        continue\n",
    "    df = data[stock]\n",
    "    \n",
    "    df['SPY Return'] = SPY_return\n",
    "    df['Excess Return'] = df['Return'] - df['SPY Return']\n",
    "    \n",
    "    data[stock] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We form winning and losing portfolios based on cumulative returns during the last 3 years, and we observe the performance of these portfolios during the next 3 years. We repeat this for each non-overlapping 3-year block, starting from 2000 all the way to 2017. First, we decide that a winning and losing portfolio is just the best performing/worst performing stock. We then find the average cumulative excess return after portfolio formation for all 3-year periods, and take the difference between the losing portfolio and winning portfolio. We then compute a t-statistic for significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3-year ranges during which we observe cumulative returns.\n",
    "year_ranges = [[2000, 2001, 2002], [2003, 2004, 2005], \n",
    "               [2006, 2007, 2008], [2009, 2010, 2011], \n",
    "               [2012, 2013, 2014], [2015, 2016, 2017]]\n",
    "winning_port = []\n",
    "losing_port = []\n",
    "\n",
    "# For each 3-year range, observe the cumulative returns in the previous \n",
    "# 3 years, for winning and losing portfolios, and then observe the \n",
    "# returns of these portfolios in the next 3 years.\n",
    "for i in range(6):\n",
    "    year_range = year_ranges[i]\n",
    "    excess_returns = {}\n",
    "    \n",
    "    for stock in data.keys():\n",
    "        if stock == 'SPY':\n",
    "            continue\n",
    "        df = data[stock]\n",
    "        \n",
    "        df = df[df.apply(lambda row: row['Year'] in year_range, axis=1)]\n",
    "        cer = df['Excess Return'].sum()\n",
    "        excess_returns[stock] = cer\n",
    "        \n",
    "    excess_returns = sorted(list(zip(excess_returns.keys(), excess_returns.values())), key=lambda a: a[1])\n",
    "    losing_port.append(list(excess_returns[0]))\n",
    "    winning_port.append(list(excess_returns[-1]))\n",
    "    \n",
    "    # Note: since we don't have complete 2020 data, we only observe \n",
    "    # the cumulative returns in 2018 and 2019 for portfolios made at \n",
    "    # the end of 2017.\n",
    "    if i == 5:\n",
    "        next_year_range = [2018, 2019]\n",
    "    else:\n",
    "        next_year_range = year_ranges[i + 1]\n",
    "        \n",
    "    df = data[losing_port[-1][0]]\n",
    "    df = df[df.apply(lambda row: row['Year'] in next_year_range, axis=1)]\n",
    "    losing_port[-1].append(df['Excess Return'].sum())\n",
    "    \n",
    "    df = data[winning_port[-1][0]]\n",
    "    df = df[df.apply(lambda row: row['Year'] in next_year_range, axis=1)]\n",
    "    winning_port[-1].append(df['Excess Return'].sum())\n",
    "\n",
    "winning_port = np.array(winning_port)\n",
    "losing_port = np.array(losing_port)\n",
    "\n",
    "# Find the average cumulative returns of the winning and losing \n",
    "# portfolios, and compute a t-statistic to find significance.\n",
    "acarw = np.mean(winning_port[:, 2].astype(float))\n",
    "acarl = np.mean(losing_port[:, 2].astype(float))\n",
    "s_sqrd = (np.sum(np.power(winning_port[:, 2].astype(float) - acarw, 2)) + \n",
    "          np.sum(np.power(losing_port[:, 2].astype(float) - acarl, 2))) / 2 * (6 - 1)\n",
    "\n",
    "print(\"ACARl - ACARw: {}\".format(acarl - acarw))\n",
    "print(\"Pooled estimate of population variance: {}\".format(s_sqrd))\n",
    "print(\"t-statistic: {}\".format((acarl - acarw) / np.sqrt(2 * s_sqrd / 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't very interesting. First, there is no significance, and second, it seems that the difference leans a bit on the negative side. Why might these two things be the case?\n",
    "\n",
    "Below, we now decide that a winning portfolio is the top 5 best performing stocks, and a losing portfolio is the bottom 5 worst performing stocks. Let's repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_ranges = [[2000, 2001, 2002], [2003, 2004, 2005], \n",
    "               [2006, 2007, 2008], [2009, 2010, 2011], \n",
    "               [2012, 2013, 2014], [2015, 2016, 2017]]\n",
    "winning_port = []\n",
    "losing_port = []\n",
    "winning_car = []\n",
    "losing_car = []\n",
    "\n",
    "for i in range(6):\n",
    "    year_range = year_ranges[i]\n",
    "    excess_returns = {}\n",
    "    \n",
    "    for stock in data.keys():\n",
    "        if stock == 'SPY':\n",
    "            continue\n",
    "        df = data[stock]\n",
    "        \n",
    "        df = df[df.apply(lambda row: row['Year'] in year_range, axis=1)]\n",
    "        cer = df['Excess Return'].sum()\n",
    "        excess_returns[stock] = cer\n",
    "        \n",
    "    excess_returns = sorted(list(zip(excess_returns.keys(), excess_returns.values())), key=lambda a: a[1])\n",
    "    losing_port.append(np.array(excess_returns[0:5]))\n",
    "    winning_port.append(np.array(excess_returns[::-1][0:5]))\n",
    "    \n",
    "    if i == 5:\n",
    "        next_year_range = [2018, 2019]\n",
    "    else:\n",
    "        next_year_range = year_ranges[i + 1]\n",
    "        \n",
    "    carl = 0\n",
    "    for stock in losing_port[-1][:, 0]:\n",
    "        df = data[stock]\n",
    "        df = df[df.apply(lambda row: row['Year'] in next_year_range, axis=1)]\n",
    "        carl += df['Excess Return'].sum()\n",
    "    losing_car.append(carl / len(losing_port[-1][:, 0]))\n",
    "    \n",
    "    carw = 0\n",
    "    for stock in winning_port[-1][:, 0]:\n",
    "        df = data[stock]\n",
    "        df = df[df.apply(lambda row: row['Year'] in next_year_range, axis=1)]\n",
    "        carw += df['Excess Return'].sum()\n",
    "    winning_car.append(carw / len(winning_port[-1][:, 0]))\n",
    "\n",
    "acarw = np.mean(winning_car)\n",
    "acarl = np.mean(losing_car)\n",
    "s_sqrd = (np.sum(np.power(winning_car - acarw, 2)) + \n",
    "          np.sum(np.power(losing_car - acarl, 2))) / 2 * (6 - 1)\n",
    "(acarl - acarw) / np.sqrt(2 * s_sqrd / 6)\n",
    "\n",
    "print(\"ACARl - ACARw: {}\".format(acarl - acarw))\n",
    "print(\"Pooled estimate of population variance: {}\".format(s_sqrd))\n",
    "print(\"t-statistic: {}\".format((acarl - acarw) / np.sqrt(2 * s_sqrd / 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our results are still insignificant, but the difference in average cumulative returns between the losing and winning portfolios maybe started leaning more towards the positive side. Why might this change have come about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "As we foreshadowed earlier, De Bondt and Thaler showed with strong confidence that people overreact to news, whereas our results are not conclusive in any way. What changes should we make in our study to try to have solid evidence in favor of the hypothesis that people overreact to news?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
